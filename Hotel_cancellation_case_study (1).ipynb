{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ca48ae",
   "metadata": {},
   "source": [
    "#### In this case study we are building a machine learning model which Predicts Hotel Booking Cancellation in \n",
    "#### Portugal Project. It will try to predict whether a booking will be cancelled or a \n",
    "#### booking will not be cancelled using machine learning based on historical data.\n",
    "#### Another Goals of this project is to find out the characteristic of customers who cancelled \n",
    "#### and finding a pattern in cancelled booking by doing an exploratory data analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c590d29",
   "metadata": {},
   "outputs": [],
   "source": [
    " Importing all the required libraries for the project.\n",
    "\n",
    "\n",
    "# Data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualization\n",
    "import #matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Filter warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report, RocCurveDisplay, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file data\n",
    "\n",
    "hotel_data=pd.read_csv(\"C:\\\\Users\\\\admin\\\\Downloads\\\\hotel_bookings.csv\")\n",
    "hotel_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9014978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial data exploration to find total number of columns and rows of our dataset and to find the data type of each column\n",
    "\n",
    "hotel_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2d507",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e916b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56c93a",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead3f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the percentage of all the null values in every column\n",
    "\n",
    "hotel_data.isnull().sum()/len(hotel_data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9118c8dd",
   "metadata": {},
   "source": [
    "##### **From above we can caonclude that 94% percent of data in column \"company\" is missing hence we can drop that column and other columns where there are  null values we can treat it by imputing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f08c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping column \"company\"\n",
    "\n",
    "hotel_data=hotel_data.drop(['company'], axis=1)\n",
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2efedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing null values for columns- \"country\",\"agent\",\"children\"\n",
    "\n",
    "hotel_data[\"agent\"]=hotel_data[\"agent\"].fillna(hotel_data[\"agent\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data[\"children\"]=hotel_data[\"children\"].fillna(hotel_data[\"children\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as percentage of missing values in \"country\" column is 0.4% so here I am using fillna approach to impute null values\n",
    "hotel_data[\"country\"]=hotel_data[\"country\"].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62172e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d186705",
   "metadata": {},
   "source": [
    "#### **From above we can see that our data is now free from all the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9123e7",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a768f06",
   "metadata": {},
   "source": [
    "#### In this part, I would like to visualize some features and show statistical relationship with target variable. This analysis will help to get overall view and deep familiarity of the data, detect extreme values and identify obvious errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe86832",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7955b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising no. of booking v/s type of hotel. According to data we have two types hotel\n",
    "# and here we are going to visualise which type has most no.of bookings\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.countplot(x='hotel', data = hotel_data, palette=\"rocket\")\n",
    "plt.title('Hotel Types', weight='bold')\n",
    "plt.xlabel('Hotel', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a3f39",
   "metadata": {},
   "source": [
    "#### **From above graph we can see no of bookings count is more in city hotel than resort hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this graph we are going to visualise no. of cancellation v/s no. of bookings. \n",
    "# This graph will tell us how many booking are being cancelled out of total booking\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.countplot(x='is_canceled', data = hotel_data, palette=\"cubehelix\")\n",
    "plt.title(\"Cancellation v/s no. of booking\", weight='bold')\n",
    "plt.xlabel('no. of cancellation', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905fe50",
   "metadata": {},
   "source": [
    "#### **From the above we can conclude that approx 63% people did not cancel their booking and approx 37% did cancel hence data is slightly imbalaced but not highly imbalaced so there is not actual need of using oversampling or undersmapling technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e797bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to visualise cancellation done by different type of customers out of total no. of bookings done by them.\n",
    "\n",
    "group_customertype_cancel = hotel_data.groupby([ 'customer_type', 'is_canceled']).size().unstack()\n",
    "group_customertype_cancel.plot(kind='bar', stacked=True, cmap='spring', figsize=(6,6))\n",
    "plt.title('Customer Type vs Booking Cancellation Status', weight='bold')\n",
    "plt.xlabel('Type of customer', fontsize=12)\n",
    "plt.xticks(rotation=360)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4bb152",
   "metadata": {},
   "source": [
    "#### **From above Graph we can conclude that most of the bookings and cancellation are done by Transient customers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458b8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising no. of booking from top 10 countries.\n",
    "\n",
    "plt.figure(figsize=(6,16))\n",
    "sns.countplot(x='country', data=hotel_data, \n",
    "              order=pd.value_counts(hotel_data['country']).iloc[:10].index, palette=\"brg\")\n",
    "plt.title('Top 10 Country of Origin', weight='bold')\n",
    "plt.xlabel('Country', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d3334",
   "metadata": {},
   "source": [
    "#### **From above we concluded that almost 40% of the booking are done from Portugal itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Market_segment\" feature exploration\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.countplot(x=hotel_data['market_segment'], palette='spring_r', \n",
    "              order=pd.value_counts(hotel_data['market_segment']).index)\n",
    "plt.title('Market Segment Types', weight='bold')\n",
    "plt.xlabel('Market Segment', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa40083",
   "metadata": {},
   "source": [
    "#### **From above we concluded that most of the bookings are done via Online Travel Agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph to show change in average daily rate of different types of rooms.\n",
    "\n",
    "data = hotel_data[hotel_data['is_canceled'] == 0]\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.catplot(data=data,x=\"reserved_room_type\",y=\"adr\",hue=\"hotel\",height=5, aspect=.8)\n",
    "plt.title('ADR v/s Type of reserved rooms in different hotel', weight='bold')\n",
    "plt.xlabel('Type of Rooms', fontsize=12)\n",
    "plt.ylabel('ADR', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329093c",
   "metadata": {},
   "source": [
    "#### **From above graph we can conclude that Average daily rate varies with the type of room reserved by guest in different types of hotel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9674adc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to visualise how ADR varies in different months in different hotels.\n",
    "\n",
    "data = hotel_data[hotel_data['is_canceled'] == 0]\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "sns.catplot(data=data,x=\"arrival_date_month\",y=\"adr\",hue=\"hotel\",height=5,aspect=2,palette='spring_r')\n",
    "plt.title('ADR v/s Different months in different hotels', weight='bold')\n",
    "plt.xlabel('Months', fontsize=12)\n",
    "plt.ylabel('ADR', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55584a",
   "metadata": {},
   "source": [
    "#### **From above graph we can conclude that most of the bookings are done in Spring and summer season of Portugal. ADR goes down from the month of September to February. Also most of the bookings are from Resort hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now going to visualise no. of booking cancellation in different months because of ADR.\n",
    "\n",
    "hotel_data['adr'] = hotel_data['adr'].astype(float)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x='arrival_date_month', y='adr', hue='is_canceled', dodge=True, palette= 'PuBu_r', data=hotel_data)\n",
    "plt.title('Arrival Month vs ADR vs Booking Cancellation Status', weight='bold')\n",
    "plt.xlabel('Arrival Month', fontsize=12)\n",
    "plt.ylabel('ADR', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1e5e1",
   "metadata": {},
   "source": [
    "#### **Here we have concluded that as Average daily rate is high in spring and summer due to which most of the cancellation are done in same season due to high rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb33508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now going to visualise the impact of special request on the no. of cancellation out of total bookings.\n",
    "\n",
    "group_cancel_request = hotel_data.groupby([ 'total_of_special_requests', 'is_canceled']).size().unstack()\n",
    "group_cancel_request.plot(kind='bar', stacked=True, cmap='Accent', figsize=(6,6))\n",
    "plt.title('Total Special Request vs Booking Cancellation Status', weight='bold')\n",
    "plt.xlabel('Number of Special Request', fontsize=12)\n",
    "plt.xticks(rotation=360)\n",
    "plt.ylabel('Count', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6076450",
   "metadata": {},
   "source": [
    "#### **From above graph we can clearly see that almost 40% of the bookings are canceled when no special rquest is made by Guest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now as we can see children and babies make no difference so we will combine these two features to make one\n",
    "\n",
    "hotel_data['all_children'] = hotel_data['children'] + hotel_data['babies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ccaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data=hotel_data.drop([\"children\",\"babies\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c9f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d08e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbe84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting type of column \"all_children\"\n",
    "\n",
    "hotel_data['all_children']= hotel_data['all_children'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f44b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding correlation of each column with each other\n",
    "\n",
    "plt.figure(figsize = (24, 12))\n",
    "\n",
    "corr = hotel_data.corr()\n",
    "sns.heatmap(corr, annot = True, linewidths = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e678d9",
   "metadata": {},
   "source": [
    "### _From above heatmap we can conclude that feature \"hotel\" ,\"reserved_room_type\",\"previous__booking_not_canceled\" and market_segment\" are strongly correlated with \"agent\",\"assigned_room_type\" ,\"previous_cancellations\"and \"distribution channel\". Hence we can drop \"agent\",\"assigned_room_type\" ,\"previous_cancellations\" and \"distribution channel\" from data. Also we can see  ,\"arrival_date_day_of_month\" ,\"days_in_waiting_list\" and \"arrival_date_week_number\" are not much correlated with \"is_canceled\" hence not providing much insight about no. of cancellation. Therefore we will drop these two features as well_\n",
    "\n",
    "### _Also reservation_status is a categorical feature that indicates the current status of a reservation. It can have values like 'Canceled', 'Check-Out', and 'No-Show'. This feature is directly related to the target variable is_canceled for the following reasons:\n",
    "\n",
    "##### If the reservation_status is 'Canceled', it implies that is_canceled should be 1.\n",
    "##### Similarly, if the reservation_status is 'Check-Out', it implies that the booking was not canceled, and hence is_canceled should be 0.\n",
    "##### Therefore, knowing the reservation_status directly gives us the value of the target variable, leading to data leakage if it is used as a feature in the model. So, it is important to remove this feature to build a model that can actually predict cancellations. Therefore, reservation_status is considered as an irrelevant feature and should be omitted.\n",
    "\n",
    "### _Since reservation_status_date includes date type data which also is directly related to target variable as change in this date can provide us direct info whether booking was canceled before that date or not. hence we will omit this too._\n",
    "\n",
    "### _We can also drop arrival_date_year as it is only providing information for certain years hence can not be used for future predictions therefore it can be considered as irrelevant features._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d1a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data=hotel_data.drop([\"agent\",\"assigned_room_type\",\"distribution_channel\",\n",
    "                            \"arrival_date_week_number\",\"reservation_status_date\",\n",
    "                            \"previous_cancellations\",\"arrival_date_day_of_month\",\n",
    "                            \"days_in_waiting_list\",\"reservation_status\",\"arrival_date_year\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ea426",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1d278",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cadfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257b791",
   "metadata": {},
   "source": [
    "#### **From above we can now see that data is left with 1 float dtype column, 12 int dtype column and 8 object i.e string dtype columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bae127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing the columns that are categorical in terms of their categories.\n",
    "\n",
    "categorical_columns = [\n",
    "    'hotel',\n",
    "    'arrival_date_month',\n",
    "    'meal',\n",
    "    'country',\n",
    "    'market_segment',\n",
    "    'is_repeated_guest',\n",
    "    'reserved_room_type',\n",
    "    'deposit_type',\n",
    "    'agent',\n",
    "    'customer_type']\n",
    "\n",
    "# Converting them to string dtype i. object\n",
    "\n",
    "for column in categorical_columns:\n",
    "    if column in hotel_data.columns:\n",
    "        hotel_data[column] = hotel_data[column].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69764b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a44e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statisticals for categorical data\n",
    "hotel_data.describe(include=\"object\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b1faf",
   "metadata": {},
   "source": [
    "#### _Here we can see column country has 177 unique values which is quite large to handle hence for ease we can drop this feature as well._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data=hotel_data.drop([\"country\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b0d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for numerical data\n",
    "\n",
    "hotel_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478bbd8",
   "metadata": {},
   "source": [
    "### **From above statistics we can see there is some noisy data in column adr,all_children and adults.\n",
    "\n",
    "#### \"adr\"= there are negetive values in this column which is absurd as this column provides us information regarding average daily rate and that can't be negative.\n",
    "#### \"adults\"= there is 0 value in adult column that means there is no adult and it can't be possible for a child to check in hotel without adult.\n",
    "#### \"all_children\"= There is max value of 10 children in one column which is quite unusual hence considered as outlier and should be omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2f7c6",
   "metadata": {},
   "source": [
    "# Handling Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = {\n",
    "    'adr':      hotel_data[hotel_data['adr'] < 0],\n",
    "    'adults':   hotel_data[hotel_data['adults'] == 0],\n",
    "    'all_children': hotel_data[hotel_data['all_children'] == 10],}\n",
    "\n",
    "noisy_data_count = {key: len(value) for key, value in noisy_data.items()}\n",
    "noisy_data_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76d174",
   "metadata": {},
   "source": [
    "#### ** Here we can see that there is one negative adr value therefore we will replace it with median, 386 rows with adult 0 so it is better we remove rows with 0 adults as values is not that big so removing rows won't impact our data that much and 2 columns with children 10 which is considered as oulier since it is unusuaaly large from other values of that column hence should be omitted.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75044a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace negative adr with median of adr column\n",
    "hotel_data.loc[hotel_data['adr'] < 0, 'adr'] = hotel_data['adr'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aaff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows with 0 adults\n",
    "hotel_data=hotel_data.loc[hotel_data[\"adults\"]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting rows with 10 children\n",
    "hotel_data=hotel_data.loc[hotel_data[\"all_children\"]!=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c07ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index\n",
    "hotel_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ffc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if noisy data is treated or not.\n",
    "noisy_data_handled = {\n",
    "    'adr': hotel_data[hotel_data['adr'] < 0],\n",
    "    'adults': hotel_data[hotel_data['adults'] == 0],\n",
    "    'all_children': hotel_data[hotel_data['all_children'] == 10]}\n",
    "\n",
    "noisy_data_handled_count = {key: len(value) for key, value in noisy_data_handled.items()}\n",
    "noisy_data_handled_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd51f35",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding- it is used for data which is not in order.\n",
    "# Label encoding- it is used for data which is in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b078fba",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "The following features are nominal variables and should be one-hot encoded:\n",
    "\n",
    "`hotel`\n",
    "\n",
    "`meal`\n",
    "\n",
    "`market_segment`\n",
    "\n",
    "`reserved_room_type`\n",
    "\n",
    "`deposit_type`\n",
    "\n",
    "`customer_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25627ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = ['hotel', 'meal', 'market_segment', 'reserved_room_type', 'deposit_type', 'customer_type',\"is_repeated_guest\"]\n",
    "hotel_data = pd.get_dummies(hotel_data, columns=one_hot_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d0f51",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "\n",
    "The following feature is an ordinal variable and should be label encoded:\n",
    "\n",
    "`arrival_date_month`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', \n",
    "          'August', 'September', 'October', 'November', 'December']\n",
    "hotel_data[\"arrival_date_month\"]= hotel_data[\"arrival_date_month\"].apply(lambda i:months.index(i)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e0f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dfae18",
   "metadata": {},
   "source": [
    "# Model Training and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab40dc55",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= hotel_data.drop([\"is_canceled\"],axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e88fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= hotel_data[\"is_canceled\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.80,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3325da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90dd17",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645db358",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_base = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfb1b8",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_clf_hyperparameters(clf, param_grid, X_train, y_train, scoring='f1', n_splits=5):\n",
    "    '''\n",
    "    This function optimizes the hyperparameters for a classifier by searching over a specified hyperparameter grid. \n",
    "    It uses GridSearchCV and cross-validation (StratifiedKFold) to evaluate different combinations of hyperparameters. \n",
    "    The combination with the highest F1-score for class 1 (canceled bookings) is selected as the default scoring metric. \n",
    "    The function returns the classifier with the optimal hyperparameters.\n",
    "    '''\n",
    "# Create the cross-validation object using StratifiedKFold to ensure the class distribution is the same across all the folds\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "    clf_grid = GridSearchCV(clf, param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "    best_hyperparameters = clf_grid.best_params_\n",
    "# Return best_estimator_ attribute which gives us the best model that has been fitted to the training data\n",
    "    return clf_grid.best_estimator_, best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for DT\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [13, 14, 15],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'class_weight': [{0: 1, 1: w} for w in [1, 2, 3]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8b36d",
   "metadata": {},
   "source": [
    "##### Since the data is slightly imbalanced and we want to optimize for class 1, we have included the class_weight parameter in our grid. In the grid above, the weight for class 0 is always 1, while the weight for class 1 varies from 1 to 5. This will help the model to focus more on class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d97e31d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tune_clf_hyperparameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Call the function for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_dt, best_dt_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mtune_clf_hyperparameters\u001b[49m(dt_base, param_grid_dt, X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tune_clf_hyperparameters' is not defined"
     ]
    }
   ],
   "source": [
    "# Call the function for hyperparameter tuning\n",
    "best_dt, best_dt_hyperparams = tune_clf_hyperparameters(dt_base, param_grid_dt, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Optimal Hyperparameters: \\n', best_dt_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7c942",
   "metadata": {},
   "source": [
    "### Dt Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calculator(clf, X_test, y_test, model_name):\n",
    "    '''\n",
    "    This function calculates all desired performance metrics for a given model on test data.\n",
    "    The metrics are calculated specifically for class 1.\n",
    "    '''\n",
    "    y_pred = clf.predict(X_test)\n",
    "    result = pd.DataFrame(data=[accuracy_score(y_test, y_pred),\n",
    "                                precision_score(y_test, y_pred, pos_label=1),\n",
    "                                recall_score(y_test, y_pred, pos_label=1),\n",
    "                                f1_score(y_test, y_pred, pos_label=1),\n",
    "                                roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])],\n",
    "                          index=['Accuracy','Precision (Class 1)','Recall (Class 1)','F1-score (Class 1)','AUC (Class 1)'],\n",
    "                          columns = [model_name])\n",
    "    \n",
    "    result = (result * 100).round(2).astype(str) + '%'                            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(clf, X_train, X_test, y_train, y_test, model_name):\n",
    "    '''\n",
    "    This function provides a complete report of the model's performance including classification reports, \n",
    "    confusion matrix and ROC curve.\n",
    "    '''\n",
    "    sns.set(font_scale=1.2)\n",
    "    \n",
    "    # Generate classification report for training set\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    print(\"\\n\\t  Classification report for training set\")\n",
    "    print(\"-\"*55)\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "    # Generate classification report for test set\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    print(\"\\n\\t   Classification report for test set\")\n",
    "    print(\"-\"*55)\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "     # Create figure and subplots \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5), dpi=100, gridspec_kw={'width_ratios': [2, 2, 1]})\n",
    "    \n",
    "    # Define a colormap\n",
    "    royalblue = LinearSegmentedColormap.from_list('royalblue', [(0, (1,1,1)), (1, (0.25,0.41,0.88))])\n",
    "    royalblue_r = royalblue.reversed()\n",
    "\n",
    "    # Plot confusion matrix for test set\n",
    "    ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test, colorbar=False, cmap=royalblue_r, ax=ax1)\n",
    "    ax1.set_title('Confusion Matrix for Test Data')                                     \n",
    "    ax1.grid(False)\n",
    "    \n",
    "    # Plot ROC curve for test data and display AUC score \n",
    "    RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax2)\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curve for Test Data (Positive label: 1)')\n",
    "    \n",
    "    # Report results for the class specified by positive label\n",
    "    result = metrics_calculator(clf, X_test, y_test, model_name)\n",
    "    table = ax3.table(cellText=result.values, colLabels=result.columns, rowLabels=result.index, loc='center')\n",
    "    table.scale(0.6, 2)\n",
    "    table.set_fontsize(12)\n",
    "    ax3.axis('tight')\n",
    "    ax3.axis('off')\n",
    "    # Modify color \n",
    "    for key, cell in table.get_celld().items():\n",
    "        if key[0] == 0:\n",
    "            cell.set_color('royalblue')\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d416f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(best_dt, X_train, X_test, y_train, y_test, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d75660",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_result = metrics_calculator(best_dt, X_test, y_test, 'Decision Tree')\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53f607",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10129596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_base = RandomForestClassifier(random_state=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid_rf = {\n",
    "#     'n_estimators': [100, 150],\n",
    "#     'criterion': ['entropy'],\n",
    "#     'max_depth': [16, 18],\n",
    "#     'min_samples_split': [2, 3, 4],\n",
    "#     'min_samples_leaf': [1, 2, 3],\n",
    "#     'class_weight': [{0: 1, 1: w} for w in [1, 2, 3]]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the tune_clf_hyperparameters function to get the best estimator\n",
    "# best_rf, best_rf_hyperparams = tune_clf_hyperparameters(rf_base, param_grid_rf, X_train, y_train)\n",
    "\n",
    "# print('RF Optimal Hyperparameters: \\n', best_rf_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1290e7b9",
   "metadata": {},
   "source": [
    "### RF Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e10b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_evaluation(best_rf, X_train, X_test, y_train, y_test, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_result = metrics_calculator(best_rf, X_test, y_test, 'Random Forest')\n",
    "# rf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab207b5c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3b1e1",
   "metadata": {},
   "source": [
    "From above we can see that Random Forest gives better accuracy than Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cb10f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc629d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2af8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa605797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
